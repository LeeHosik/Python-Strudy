{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Deep Learning 의 개요\n",
    "\n",
    "# Deep Learning\n",
    "\n",
    "- Machine Learning의 한 종류.\n",
    "- 여러 층을 가진 신경망을 사용해 Machine Learning을 수행하는 것.\n",
    "- 이미지 처리, 음성 인식, 자연어 처리에 중점.\n",
    "- 1980년대 부터 있었지만 현대에 와서 컴퓨팅 성능 향상으로 각광을 받음.\n",
    "\n",
    "### Deep Learning과 Machine Learning의 차이점\n",
    "\n",
    "- 가장 큰 차이점은 특징량(Reatures) 추출.\n",
    "\n",
    "hidden layer가 많으면 deep? 각 layer마다 가중치(y=ax+b)가 작업됨(?)\n",
    "\n",
    "```jsx\n",
    "밑에 AI\n",
    "```\n",
    "\n",
    "특히, Deep Learning은 기존의 Machine Learning과는 달리 특징량 추출을 자동으로 수행하기 때문에, Feature Engineering에 대한 노력을 크게 줄일 수 있습니다. 이러한 이유로 Deep Learning은 최근 몇 년간 매우 높은 인기를 얻고 있으며, 이미지, 음성, 자연어 처리 분야에서 혁신적인 결과를 이냅니다.\n",
    "\n",
    "또한, Deep Learning의 핵심 개념 중 하나는 Neural Network입니다. Neural Network는 인간 뇌의 신경망 구조를 모방하여 만들어진 알고리즘으로, 일종의 함수라고 볼 수 있습니다. 이 함수는 입력(Input)을 받아 여러 층의 노드를 거쳐 출력(Output)을 내보내는 과정을 거칩니다. 각 층의 노드들은 서로 다른 가중치(Weight)를 가지며, 이 가중치들이 Deep Learning의 학습을 담당합니다.\n",
    "\n",
    "하지만, Deep Learning 역시 그만큼 복잡하고 많은 데이터와 컴퓨팅 성능이 필요합니다. 그래서, 최근에는 Cloud Computing을 이용하여 더욱 높은 성능의 컴퓨팅 자원을 활용하는 추세입니다.\n",
    "\n",
    "또한 Deep Learning은 학습 데이터의 양과 질의 영향을 많이 받습니다. 충분한 양의 데이터가 없거나 데이터가 노이즈를 포함하고 있을 경우, Deep Learning 모델의 성능이 저하될 수 있습니다. 따라서 데이터 전처리 과정이 중요하며, 이를 위해서는 데이터 분석 및 전처리 기술에 대한 이해가 필요합니다.\n",
    "\n",
    "또한, Deep Learning은 모델의 구조나 하이퍼파라미터(Hyperparameter)에 따라 결과가 크게 달라질 수 있습니다. 따라서 모델의 구성과 하이퍼파라미터를 조정하는 것이 매우 중요합니다. 이를 위해 Grid Search, Random Search 등의 방법을 사용하여 최적의 모델을 찾을 수 있습니다.\n",
    "\n",
    "최근에는 Deep Learning을 활용한 다양한 분야의 연구가 활발하게 이루어지고 있습니다. 예를 들어, 의료 분야에서는 딥러닝을 이용하여 질병 진단 및 치료에 활용하고 있으며, 자율 주행 자동차 분야에서는 이미지 및 센서 데이터를 이용하여 차량 제어 시스템을 개발하는 등의 연구가 이루어지고 있습니다.\n",
    "\n",
    "딥러닝에서 학습을 시킬 때는 많은 양의 데이터와 컴퓨팅 성능이 필요합니다. 이러한 이유로 최근에는 클라우드 컴퓨팅을 활용하여 더욱 높은 성능의 컴퓨팅 자원을 활용하고 있습니다. 또한, Deep Learning 모델의 성능이 데이터 전처리 과정에서 크게 좌우됩니다. 따라서 데이터 분석 및 전처리 기술에 대한 이해가 필요합니다.\n",
    "\n",
    "또한, 딥러닝 모델의 구조나 하이퍼파라미터에 따라 결과가 크게 달라질 수 있습니다. 이러한 이유로 모델의 구성과 하이퍼파라미터를 조정하는 것이 매우 중요합니다. 최적의 모델을 찾기 위해 Grid Search, Random Search 등의 방법을 사용할 수 있습니다.\n",
    "\n",
    "딥러닝은 이미지, 음성, 자연어 처리 분야에서 혁신적인 결과를 이냅니다. 예를 들어, 자율 주행 자동차 분야에서는 이미지 및 센서 데이터를 이용하여 차량 제어 시스템을 개발하는 등의 연구가 이루어지고 있습니다. 또한, 의료 분야에서는 딥러닝을 이용하여 질병 진단 및 치료에 활용하고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 수능점수\n",
    "\n",
    "```jsx\n",
    "6월 : 60점\n",
    "9월 : 80점\n",
    "```\n",
    "\n",
    "```python\n",
    "# 가중치(w)가 있어야 알고리즘\n",
    "# 0.5가 가중치, 가중치를 똑같이 준것\n",
    "(60 * 0.5) + (80 * 0.5) # = 70\n",
    "\n",
    "# y = w1 * 6월 + w2 * 9월 + 절편(b)\n",
    "# b가 뭐가 드 ㄹ어갈 수 있을까? 모의고사니까 문제의 난이도? 어려웠다면 - , 쉬웠다면 + ?\n",
    "```\n",
    "\n",
    "|  | 6월 | 9월 | 수능 |\n",
    "| --- | --- | --- | --- |\n",
    "| 철수 | 60 | 80 | 90 |\n",
    "| 영희 | 50 | 60 | 70 |\n",
    "| 만수 | 60 | 60 | 80 |\n",
    "\n",
    "⇒ 수능이 쉬웠다 \n",
    "\n",
    "|  | 6월 | 9월 | 수능 | 오차 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 철수 | 60 | 80 | 90 | 20 |\n",
    "| 영희 | 50 | 60 | 70 | 15 |\n",
    "| 만수 | 60 | 60 | 80 | 20 |\n",
    "\n",
    "계산 한뒤 오차가 있으니 다시 계산하고 오차가 0이 될때까지?? 최소까지? (??)\n",
    "\n",
    "수능 = target\n",
    "\n",
    "6월,9월 = feature\n",
    "\n",
    "총오차값을 계산하는 알고리즘 : Cross-Entropy , Binary Cross Entropy \n",
    "\n",
    "---\n",
    "\n",
    "### 스마트폰을 구매 할까?\n",
    "\n",
    "- 구매 : y = 1\n",
    "- No구매 : y = 0\n",
    "\n",
    "target = y\n",
    "\n",
    "Feature ?\n",
    "\n",
    "x1 : 이번달의 수입은 충분 ? (여유자금? 저금액?)\n",
    "\n",
    "x2 : 최신 기능이 있는가 ? (신상폰에)\n",
    "\n",
    "x3 : 기존 스마트폰에 문제가 있나? ( 망가짐, 오래사용, 기능저하이슈 기타 등등)\n",
    "\n",
    "2개만 만족하면 구매하는걸로 하자! 고 하면 초등학생도 하겠다\n",
    "\n",
    "y = x1 + x2 + x3 + b <<<< b가 뭘까 이제 \n",
    "\n",
    "b는 똑같지가 않어 ..\n",
    "\n",
    "이건 임의야~\n",
    "\n",
    "부자 : w1 = 1, w2 = 8, w3 = 3\n",
    "\n",
    "스마트폰에 문제있는 사람 : w1 = 3, w2 = 2, w3 = 9 \n",
    "\n",
    "이런걸 만드는게 deep learning? 이라 하심 \n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### Leep Learning을 이용한 계산\n",
    "\n",
    "- 실제 Data를 이용하여 오차를 구한 후 그 오차들의 합을 구한다.\n",
    "- 이때 오차들의 합이 가장 적었을때의 w값을 취하면 된다.\n",
    "- 오차를 구할때 그냥 뺄셈만 이용하면 minus값이 발생하는 경우가 발생한다.\n",
    "- 이를 해결하기 위해 절대값 오차, 평균제곱오차(오차 값들의 제곱의 합계)를 계산한다.\n",
    "\n",
    "### Loss Function(손실함수)\n",
    "\n",
    "- 평균 제곱 오차를 구하여 최소화 시키는 방법\n",
    "- 모델의 정확도를 평가하는 함수\n",
    "    \n",
    "    (정확도는 오르고 손실값은 떨어져야함)\n",
    "    \n",
    "\n",
    "### Activation Function(활성함수)\n",
    "\n",
    "ai = \n",
    "\n",
    "활성 함수(Activation Function)은 신경망에서 입력 신호의 총합을 출력 신호로 변환하는 함수입니다. 이 함수는 비선형 함수(nonlinear function)이어야 합니다. 이유는 선형 함수를 사용하면 여러 층의 은닉층을 갖는 의미 있는 신경망을 구성할 수 없기 때문입니다. 대표적인 활성 함수로는 sigmoid, tanh, ReLU 등이 있습니다.\n",
    "\n",
    "가중치와 절편을 곱해서 하나의 값을 만들기 위해서 쓴다 ?\n",
    "\n",
    "sigmoid = 0 ~ 1\n",
    "\n",
    "tanh = -1 ~ 1 \n",
    "\n",
    "ReLU (렐루) 는 이미지에서 제일 많이 씀 → 무조건 -는 0값이고 양수는 살림 \n",
    "\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2e4dc111-fa8e-4299-a8bf-f68b49cfad91/Untitled.png)\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "ai = \n",
    "\n",
    "Learning Rate(학습률)은 Gradient Descent 알고리즘에서, 한 번의 학습 단계에서 얼마나 많이 학습해야 할지를 결정하는 하이퍼파라미터입니다. Learning Rate이 너무 작으면 학습이 느리게 이루어지고, 너무 크면 학습이 불안정해지고 발산할 수 있습니다. 이를 조절하여 최적의 학습 속도를 찾아내는 것이 중요합니다.\n",
    "\n",
    "y = (learning rate) * w1 * x1 + b \n",
    "\n",
    "?????? 기울기만 빼지말고 러닝레이트도 곱한 뒤에 빼자 라고 말씀하시는데 일단 잘 이해 안됬음\n",
    "\n",
    "Learning Rate Optimizer \n",
    "\n",
    "- momentum : 가속도를 유지 ( 강하학습에 간격을 유지)\n",
    "- AdaGrad : 자주 변하는 w는 작게, 자주 변하지 않는 w는 크게\n",
    "    \n",
    "    AdaGrad는 gradient descent를 위한 최적화 알고리즘 중 하나로, 학습률을 파라미터에 적응시킵니다. 그래디언트의 역사적인 제곱값의 합으로 나누어 학습률을 스케일링합니다.\n",
    "    \n",
    "- RMSProp : AdaGrad인데 제곱\n",
    "- Adam : RMSProp + Mementum <<< 요즘은 이거 많이 쓴다 하심\n",
    "\n",
    "## Forward Propagation (순전파)\n",
    "\n",
    "## Backward Propagation ( 역전파)\n",
    "\n",
    "deep learning은 기본적으로 과대적합이 일어남 \n",
    "\n",
    "column이 많아서 \n",
    "\n",
    "## Drop out\n",
    "\n",
    "- 은닉층에 서 어느정도 안쓸지 정하는것\n",
    "- sample마다 안쓰는게 다르다 (?)\n",
    "\n",
    "## Early Stopping (조기종료)\n",
    "\n",
    "- 여기가 best야 할때 멈춤\n",
    "    - patients : best에서 얼마만큼 더 가서 거기까지 함 확인해보겠다고 지정하는 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d864e386a55a2cee39c31bc0e2325312cb68f97ec75faaaf5382620c119f58c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
