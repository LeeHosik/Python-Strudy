{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input,train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 과 valid data 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = train_input / 255 # < data가 0~255 라서 255, 1~256일땐 256\n",
    "train_scaled = train_scaled.reshape(-1,28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer를 추가하는 방법 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 만들기\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)) #은닉층 만들기, sigmoid로 100개\n",
    "dense2 = keras.layers.Dense(10, activation='softmax') #출력층, fashion의 target이 10개임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 모델에 층을 추가\n",
    "model = keras.Sequential([dense1,dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Param = parameter \n",
    "# input 784 x 100 = 78400 + bias(100), 100개의 은닉층에 b가 1개씩 들어 있으니 b가 100개 더해져서 78500 \n",
    "# 출력층도 10x100 + b(10개) = 1010\n",
    "\n",
    "# Total params: 79,510"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer를 추가하는 방법2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid',input_shape=(784,), name='hiddenLayer'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='outputLayer')\n",
    "], name = 'fashionNNIST_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fashionNNIST_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hiddenLayer (Dense)         (None, 100)               78500     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer를 추가하는 방법 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hiddenLayer'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='outputLayer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hiddenLayer (Dense)         (None, 100)               78500     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 1s 654us/step - loss: 0.3331 - accuracy: 0.8797\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 1s 645us/step - loss: 0.3201 - accuracy: 0.8834\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 1s 607us/step - loss: 0.3087 - accuracy: 0.8878\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 1s 608us/step - loss: 0.2993 - accuracy: 0.8914\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 1s 610us/step - loss: 0.2909 - accuracy: 0.8937\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 1s 632us/step - loss: 0.2826 - accuracy: 0.8983\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 1s 633us/step - loss: 0.2744 - accuracy: 0.8983\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 1s 669us/step - loss: 0.2673 - accuracy: 0.9028\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 1s 642us/step - loss: 0.2605 - accuracy: 0.9047\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 1s 635us/step - loss: 0.2550 - accuracy: 0.9083\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 1s 630us/step - loss: 0.2478 - accuracy: 0.9105\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 1s 609us/step - loss: 0.2438 - accuracy: 0.9111\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 1s 616us/step - loss: 0.2379 - accuracy: 0.9129\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 1s 649us/step - loss: 0.2332 - accuracy: 0.9142\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 1s 619us/step - loss: 0.2290 - accuracy: 0.9151\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 1s 620us/step - loss: 0.2225 - accuracy: 0.9197\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 1s 689us/step - loss: 0.2185 - accuracy: 0.9212\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 1s 613us/step - loss: 0.2141 - accuracy: 0.9221\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 1s 680us/step - loss: 0.2111 - accuracy: 0.9246\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 1s 640us/step - loss: 0.2069 - accuracy: 0.9257\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 1s 615us/step - loss: 0.2041 - accuracy: 0.9256\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 1s 642us/step - loss: 0.1984 - accuracy: 0.9278\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 1s 609us/step - loss: 0.1955 - accuracy: 0.9296\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 1s 609us/step - loss: 0.1921 - accuracy: 0.9315\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 1s 617us/step - loss: 0.1879 - accuracy: 0.9326\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 1s 647us/step - loss: 0.1848 - accuracy: 0.9337\n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 1s 618us/step - loss: 0.1814 - accuracy: 0.9355\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 1s 622us/step - loss: 0.1778 - accuracy: 0.9362\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 1s 611us/step - loss: 0.1764 - accuracy: 0.9383\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 1s 667us/step - loss: 0.1724 - accuracy: 0.9383\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 1s 706us/step - loss: 0.1696 - accuracy: 0.9402\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 1s 679us/step - loss: 0.1668 - accuracy: 0.9409\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 1s 653us/step - loss: 0.1640 - accuracy: 0.9419\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 1s 619us/step - loss: 0.1598 - accuracy: 0.9432\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 1s 669us/step - loss: 0.1583 - accuracy: 0.9433\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 1s 660us/step - loss: 0.1547 - accuracy: 0.9452\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 1s 666us/step - loss: 0.1533 - accuracy: 0.9459\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 1s 615us/step - loss: 0.1502 - accuracy: 0.9466\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 1s 614us/step - loss: 0.1480 - accuracy: 0.9493\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 1s 700us/step - loss: 0.1455 - accuracy: 0.9483\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 1s 657us/step - loss: 0.1435 - accuracy: 0.9490\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 1s 664us/step - loss: 0.1404 - accuracy: 0.9512\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 1s 613us/step - loss: 0.1379 - accuracy: 0.9521\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 1s 664us/step - loss: 0.1348 - accuracy: 0.9525\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 1s 739us/step - loss: 0.1329 - accuracy: 0.9532\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 1s 658us/step - loss: 0.1324 - accuracy: 0.9533\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 1s 643us/step - loss: 0.1290 - accuracy: 0.9548\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 1s 611us/step - loss: 0.1269 - accuracy: 0.9549\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 1s 621us/step - loss: 0.1249 - accuracy: 0.9560\n",
      "Epoch 50/50\n",
      "1200/1200 [==============================] - 1s 663us/step - loss: 0.1234 - accuracy: 0.9574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17fff1be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 423us/step - loss: 0.3701 - accuracy: 0.8919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.370125949382782, 0.8918750286102295]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층 추가 및 Activation 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28), name='flattenLayer')) #원래 2차원 데이터를 넣는다 함 \n",
    "model.add(keras.layers.Dense(100, activation='relu' , name='hiddenLayer')) #<< flatten이 추가되면서 여기에 input shape가 사라짐 \n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='outputLayer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flattenLayer (Flatten)      (None, 784)               0         \n",
      "                                                                 \n",
      " hiddenLayer (Dense)         (None, 100)               78500     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Flatten 은 Param은 없음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 28, 28), found shape=(32, 784)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_scaled, train_target, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/j9/zr30dj9x51x0cxznxz0064t80000gn/T/__autograph_generated_file99g3g5bk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/luchesia/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 28, 28), found shape=(32, 784)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_scaled = train_scaled.reshape(-1,28 * 28) \n",
    "여기서 reshape 해놔서 실행이 안됨 \n",
    "위에서 했던 작업중에서 reshape 만 지운뒤 다시 재실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input,train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "train_scaled = train_input / 255.0 # < data가 0~255 라서 255, 1~256일땐 256\n",
    "\n",
    "\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 1s 655us/step - loss: 0.5286 - accuracy: 0.8135\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 1s 674us/step - loss: 0.3916 - accuracy: 0.8588\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 1s 612us/step - loss: 0.3543 - accuracy: 0.8721\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 1s 613us/step - loss: 0.3298 - accuracy: 0.8811\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 1s 631us/step - loss: 0.3154 - accuracy: 0.8864\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 1s 607us/step - loss: 0.3031 - accuracy: 0.8908\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 1s 608us/step - loss: 0.2953 - accuracy: 0.8954\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 1s 643us/step - loss: 0.2822 - accuracy: 0.8982\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 1s 656us/step - loss: 0.2769 - accuracy: 0.9013\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 1s 696us/step - loss: 0.2684 - accuracy: 0.9051\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 1s 709us/step - loss: 0.2641 - accuracy: 0.9061\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 1s 664us/step - loss: 0.2569 - accuracy: 0.9089\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 1s 670us/step - loss: 0.2540 - accuracy: 0.9110\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 1s 643us/step - loss: 0.2463 - accuracy: 0.9134\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 1s 660us/step - loss: 0.2434 - accuracy: 0.9161\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.2385 - accuracy: 0.9168\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 0.2328 - accuracy: 0.9194\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 1s 611us/step - loss: 0.2284 - accuracy: 0.9206\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 1s 604us/step - loss: 0.2272 - accuracy: 0.9226\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 1s 624us/step - loss: 0.2229 - accuracy: 0.9227\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 0.2208 - accuracy: 0.9247\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 1s 604us/step - loss: 0.2176 - accuracy: 0.9257\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 1s 636us/step - loss: 0.2123 - accuracy: 0.9267\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 1s 648us/step - loss: 0.2117 - accuracy: 0.9282\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 1s 626us/step - loss: 0.2065 - accuracy: 0.9290\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 1s 631us/step - loss: 0.2062 - accuracy: 0.9295\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 1s 608us/step - loss: 0.1990 - accuracy: 0.9320\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.1987 - accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 1s 632us/step - loss: 0.1939 - accuracy: 0.9334\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 1s 605us/step - loss: 0.1899 - accuracy: 0.9357\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.1915 - accuracy: 0.9352\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.1847 - accuracy: 0.9374\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 1s 704us/step - loss: 0.1845 - accuracy: 0.9381\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 1s 638us/step - loss: 0.1826 - accuracy: 0.9396\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 1s 659us/step - loss: 0.1804 - accuracy: 0.9401\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 1s 661us/step - loss: 0.1782 - accuracy: 0.9397\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.1732 - accuracy: 0.9421\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 1s 640us/step - loss: 0.1743 - accuracy: 0.9431\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.1721 - accuracy: 0.9429\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 1s 718us/step - loss: 0.1687 - accuracy: 0.9444\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 1s 655us/step - loss: 0.1680 - accuracy: 0.9452\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 1s 606us/step - loss: 0.1679 - accuracy: 0.9458\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 1s 613us/step - loss: 0.1657 - accuracy: 0.9458\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 1s 628us/step - loss: 0.1615 - accuracy: 0.9478\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 0.1602 - accuracy: 0.9468\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 1s 617us/step - loss: 0.1590 - accuracy: 0.9480\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 1s 632us/step - loss: 0.1546 - accuracy: 0.9500\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.1584 - accuracy: 0.9497\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 1s 647us/step - loss: 0.1549 - accuracy: 0.9501\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 1s 632us/step - loss: 0.1500 - accuracy: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17fac51c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 411us/step - loss: 0.6590 - accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6590100526809692, 0.8840000033378601]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적화 알고리즘 optimizer를 하나도 사용하지 않았음.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "SGD 경사하강법 -> momentum\\\n",
    "RMSprop\\\n",
    "momentum + RMSprop = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 (확률적 경사 하강법) - 1\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 ( 확률적 경사 하강법 ) - 2\n",
    "\n",
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 (Momentum)\n",
    "momentum = keras.optimizers.SGD(momentum=0.9, nesterov=True) # nesterov 이동하는 거리 측정 \n",
    "model.compile(optimizer=momentum, loss='sparse_categorical_crossentropy', metrics= 'accuracy')\n",
    "\n",
    "# ** # ** 이녀석만 따로 해야댐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 (Adagrad)\n",
    "model.compile(optimizer='adagrad', loss='sparse_categorical_crossentropy', metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 (RMSprop)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용방법 (Adam)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics= 'accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation 함수 : Relu\\\n",
    "Optimizer :  Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.5211 - accuracy: 0.8185\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.3920 - accuracy: 0.8606\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.3547 - accuracy: 0.8720\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 0.3310 - accuracy: 0.8783\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.3070 - accuracy: 0.8865\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.2900 - accuracy: 0.8937\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.2776 - accuracy: 0.8980\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 0.2661 - accuracy: 0.9022\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.2568 - accuracy: 0.9038\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 1s 722us/step - loss: 0.2474 - accuracy: 0.9087\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.2398 - accuracy: 0.9101\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.2318 - accuracy: 0.9146\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.2239 - accuracy: 0.9164\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.2183 - accuracy: 0.9184\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 1s 731us/step - loss: 0.2112 - accuracy: 0.9209\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 1s 715us/step - loss: 0.2064 - accuracy: 0.9229\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.2004 - accuracy: 0.9239\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.1946 - accuracy: 0.9264\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.1922 - accuracy: 0.9281\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.1859 - accuracy: 0.9294\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 0.1840 - accuracy: 0.9307\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 0.1766 - accuracy: 0.9330\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.1727 - accuracy: 0.9347\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 0.1699 - accuracy: 0.9354\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.1654 - accuracy: 0.9379\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.1624 - accuracy: 0.9390\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.1571 - accuracy: 0.9405\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 0.1571 - accuracy: 0.9403\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.1499 - accuracy: 0.9438\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.1478 - accuracy: 0.9441\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.1446 - accuracy: 0.9454\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 1s 722us/step - loss: 0.1427 - accuracy: 0.9463\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 0.1395 - accuracy: 0.9476\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 1s 742us/step - loss: 0.1342 - accuracy: 0.9492\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 0.1336 - accuracy: 0.9500\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.1292 - accuracy: 0.9517\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 1s 717us/step - loss: 0.1287 - accuracy: 0.9521\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.1250 - accuracy: 0.9530\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.1246 - accuracy: 0.9532\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 1s 945us/step - loss: 0.1197 - accuracy: 0.9551\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 1s 761us/step - loss: 0.1185 - accuracy: 0.9554\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.1159 - accuracy: 0.9568\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.1140 - accuracy: 0.9570\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 1s 715us/step - loss: 0.1139 - accuracy: 0.9572\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 1s 739us/step - loss: 0.1108 - accuracy: 0.9590\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.1089 - accuracy: 0.9590\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.1064 - accuracy: 0.9596\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.1071 - accuracy: 0.9603\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.1044 - accuracy: 0.9607\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 1s 732us/step - loss: 0.1003 - accuracy: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ffe4040>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28), name='flattenLayer')) #원래 2차원 데이터를 넣는다 함 \n",
    "model.add(keras.layers.Dense(100, activation='relu' , name='hiddenLayer')) #<< flatten이 추가되면서 여기에 input shape가 사라짐 \n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='outputLayer'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics= 'accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d864e386a55a2cee39c31bc0e2325312cb68f97ec75faaaf5382620c119f58c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
